mydata <- read.csv("/Users/jaydangi/Downloads/h1b_petition-master/latest123.csv", header = T)
head(mydata)
data <- na.omit(mydata)
data = data[-grep("CERTIFIED-WITHDRAWN", data$CASE_STATUS),]
data = data[-grep("WITHDRAWN", data$CASE_STATUS),]
mydata <- read.csv("logit_model.csv", header = T)
str(mydata)
mydata=mydata[sample(nrow(mydata)),]
select.data=sample(1:nrow(mydata),0.8*nrow(mydata))
train=mydata[select.data,]
test=mydata[-select.data,]
str(train)
status = train$CASE_STATUS
employer = train$EMPLOYER_NAME
soc_name = train$SOC_NAME
title = train$JOB_TITLE
position_type = train$FULL_TIME_POSITION
wage = train$PREVAILING_WAGE
year = as.factor(train$YEAR)
region = train$REGION
lon = train$lon
lat = train$lat
fit <- glm(status ~ position_type + wage + year + region + soc_name, family = binomial)
summary(fit)
base=glm(status~wage,data=train,family=binomial())
summary(base)
forward=step(base,scope=list(upper=fit,lower=~1),direction="forward",trace=F)
forward
summary(forward)
backward=step(fit,scope=list(upper=fit,lower=~1),direction="backward",trace=F)
backward
summary(backward)
#Building Bestsubsetmodel
bestsubset=step(base,scope=list(upper=fit,lower=~1),direction="both",trace=F)
bestsubset
summary(bestsubset)
#Adjusted R square
null<-glm(status~1,family="binomial")
1-logLik(forward)/logLik(null)
1-logLik(backward)/logLik(null)
1-logLik(bestsubset)/logLik(null)
#Exponential for every model
exp(coef(bestsubset))
exp(coef(backward))
exp(coef(forward))
#Finding the probability on train data and saing it in excel
#best sub set model
bestsubset_predict=predict(bestsubset,type="response", newdata=train)
bestsubset_predict
#saving the predicted probability in csv on train data for best sub set model
write.csv(data.frame(predict(bestsubset,type="response",newdata=train)),"bestsubset_train.csv")
best_subset_output<-cbind(train,bestsubset_predict)
write.csv(best_subset_output,"Train_best_subset.csv")
#Forward Model
forward_predict=predict(forward,type="response", newdata=train)
forward_predict
#saving the predicted probability in csv on train data for forward model
write.csv(data.frame(predict(forward,type="response",newdata=train)),"forward_train.csv")
forward_output<-cbind(train,forward_predict)
write.csv(forward_output,"Train_forward.csv")
#Backward Model
backward_predict=predict(backward,type="response", newdata=train)
backward_predict
#saving the predicted probability in csv on train data for backward model
#write.csv(data.frame(predict(backward,type="response",newdata=train)),"backward_train.csv")
backward_output<-cbind(train,backward_predict)
write.csv(backward_output,"Train_backward.csv")
#predicting value in test model for best subset model
status = test$CASE_STATUS
employer = test$EMPLOYER_NAME
soc_name = test$SOC_NAME
title = test$JOB_TITLE
position_type = test$FULL_TIME_POSITION
wage = test$PREVAILING_WAGE
year = as.factor(test$YEAR)
region = test$REGION
test_df <- data.frame(wage,year,region,position_type,soc_name)
bestsubset_test=predict(bestsubset,type="response", newdata=test_df)
#saving predicting data on test data over best sub set model
Bestsubset_status<-ifelse(bestsubset_test > 0.59,"DENIED","CERTIFIED")
best_subset_test<-cbind(test,bestsubset_test,Bestsubset_status)
write.csv(best_subset_test,file="Test_bestsubset.csv")
library(xlsx)
#saving predicting data on test data over best sub set model
Bestsubset_status<-ifelse(bestsubset_test > 0.59,"DENIED","CERTIFIED")
best_subset_test<-cbind(test,bestsubset_test,Bestsubset_status)
write.xlsx(best_subset_test,file="Test_bestsubset.xlsx",sheetName="For 0.6")
Bestsubset_status<-ifelse(bestsubset_test > 0.69,"DENIED","CERTIFIED")
best_subset_test<-cbind(test,bestsubset_test,Bestsubset_status)
write.xlsx(best_subset_test,file="Test_bestsubset.xlsx",sheetName="For 0.7", append=TRUE)
Bestsubset_status<-ifelse(bestsubset_test > 0.79,"DENIED","CERTIFIED")
best_subset_test<-cbind(test,bestsubset_test,Bestsubset_status)
write.xlsx(best_subset_test,file="Test_bestsubset.xlsx",sheetName="For 0.8" , append=TRUE)
Bestsubset_status<-ifelse(bestsubset_test > 0.89,"DENIED","CERTIFIED")
best_subset_test<-cbind(test,bestsubset_test,Bestsubset_status)
write.xlsx(best_subset_test,file="Test_bestsubset.xlsx",sheetName="For 0.9" , append=TRUE)
# TO calculate the accuracy
accuracy_60<-table(test$CASE_STATUS, bestsubset_test > 0.59)
accuracy_60
sum(diag(accuracy_60))/sum(accuracy_60)
accuracy_70<-table(test$CASE_STATUS, bestsubset_test > 0.69)
accuracy_70
sum(diag(accuracy_70))/sum(accuracy_70)
accuracy_80<-table(test$CASE_STATUS, bestsubset_test > 0.79)
accuracy_80
sum(diag(accuracy_80))/sum(accuracy_80)
accuracy_90<-table(test$CASE_STATUS, bestsubset_test > 0.89)
accuracy_90
sum(diag(accuracy_90))/sum(accuracy_90)
# Now for the Backward
backward_test=predict(backward,type="response", newdata=test_df)
#saving predicting data on test data over backward sub set model
backward_status<-ifelse(backward_test > 0.59,"DENIED","CERTIFIED")
backward_model_test<-cbind(test,backward_test,backward_status)
write.xlsx(backward_model_test,file="Test_backward.xlsx",sheetName="For 0.6")
backward_status<-ifelse(backward_test > 0.69,"DENIED","CERTIFIED")
backward_test<-cbind(test,backward_test,backward_status)
write.xlsx(backward_model_test,file="Test_backward.xlsx",sheetName="For 0.7", append=TRUE)
backward_status<-ifelse(backward_test > 0.79,"DENIED","CERTIFIED")
backward_test<-cbind(test,backward_test,backward_status)
write.xlsx(backward_model_test,file="Test_backward.xlsx",sheetName="For 0.8" , append=TRUE)
backward_status<-ifelse(backward_test > 0.89,"DENIED","CERTIFIED")
backward_test<-cbind(test,backward_test,backward_status)
write.xlsx(backward_model_test,file="Test_backward.xlsx",sheetName="For 0.9" , append=TRUE)
# TO calculate the accuracy
accuracy_60<-table(test$CASE_STATUS, backward_test > 0.59)
accuracy_60
sum(diag(accuracy_60))/sum(accuracy_60)
accuracy_70<-table(test$CASE_STATUS, backward_test > 0.69)
accuracy_70
sum(diag(accuracy_70))/sum(accuracy_70)
accuracy_80<-table(test$CASE_STATUS, backward_test > 0.79)
accuracy_80
sum(diag(accuracy_80))/sum(accuracy_80)
accuracy_90<-table(test$CASE_STATUS, backward_test > 0.89)
accuracy_90
sum(diag(accuracy_90))/sum(accuracy_90)
# Now for Forward
forward_test=predict(forward,type="response", newdata=test_df)
#saving predicting data on test data over forward sub set model
forward_status<-ifelse(forward_test > 0.59,"DENIED","CERTIFIED")
forward_model_test<-cbind(test,forward_test,forward_status)
write.xlsx(forward_model_test,file="Test_forward.xlsx",sheetName="For 0.6")
forward_status<-ifelse(forward_test > 0.69,"DENIED","CERTIFIED")
forward_model_test<-cbind(test,forward_test,forward_status)
write.xlsx(forward_model_test,file="Test_forward.xlsx",sheetName="For 0.7", append=TRUE)
forward_status<-ifelse(forward_test > 0.79,"DENIED","CERTIFIED")
forward_model_test<-cbind(test,forward_test,forward_status)
write.xlsx(forward_model_test,file="Test_forward.xlsx",sheetName="For 0.8" , append=TRUE)
forward_status<-ifelse(forward_test > 0.89,"DENIED","CERTIFIED")
forward_model_test<-cbind(test,forward_test,forward_status)
write.xlsx(forward_model_test,file="Test_forward.xlsx",sheetName="For 0.9" , append=TRUE)
# TO calculate the accuracy
accuracy_60<-table(test$CASE_STATUS, forward_test > 0.59)
accuracy_60
sum(diag(accuracy_60))/sum(accuracy_60)
accuracy_70<-table(test$CASE_STATUS, forward_test > 0.69)
accuracy_70
sum(diag(accuracy_70))/sum(accuracy_70)
accuracy_80<-table(test$CASE_STATUS, forward_test > 0.79)
accuracy_80
sum(diag(accuracy_80))/sum(accuracy_80)
accuracy_90<-table(test$CASE_STATUS, forward_test > 0.89)
accuracy_90
sum(diag(accuracy_90))/sum(accuracy_90)
library("devtools")
library("neuralnet")
library('dplyr') # data manipulation
library('mice') # imputation
library(stringr)
library(class)
library(e1071)
library(gmodels)
install.packages(mice)
install.packages('mice')
library('mice') # imputation
setwd("/Users/jaydangi/Desktop/MySas/FinalProject")
MyData <- read.csv("h1b_kaggle.csv", header = TRUE,stringsAsFactors = F)
dim(MyData)
MyData<-na.omit(MyData)
dim(MyData)
MyData$City <- str_replace(MyData$WORKSITE, '(.+),.+', '\\1')
MyData$State <- str_replace(MyData$WORKSITE, '.+,(.+)', '\\1')
MyData$Region <-rep(1,nrow(MyData))
MyData$Region[MyData$State %in% c(' ARIZONA',' COLORADO',' IDAHO',' MONTANA', ' NEVADA',' NEW MEXICO',' UTAH',' WYOMING',' ALASKA',' CALIFORNIA',' HAWAII',' OREGON',' WASHINGTON')]<-1
MyData$Region[MyData$State %in% c(' DELAWARE',' FLORIDA',' GEORGIA',' MARYLAND',' NORTH CAROLINA',' SOUTH CAROLINA',' VIRGINIA',' WEST VIRGINIA',' DISTRICT OF COLUMBIA', ' ALABAMA', ' KENTUCKY',' MISSISSIPPI',' TENNESSEE', ' ARKANSAS',' LOUISIANA',' OKLAHOMA', ' TEXAS',' PUERTO RICO')]<-2
MyData$Region[MyData$State %in% c(' ILLINOIS',' INDIANA',' MICHIGAN',' OHIO',' WISCONSIN',' IOWA',' KANSAS',' MINNESOTA',' MISSOURI',' NEBRASKA',' NORTH DAKOTA',' SOUTH DAKOTA')]<-3
MyData$Region[MyData$State %in% c(' CONNECTICUT',' MAINE',' MASSACHUSETTS',' NEW HAMPSHIRE',' RHODE ISLAND',' NEW JERSEY',' NEW YORK',' VERMONT',' PENNSYLVANIA')]<-4
MyData$dummy=rep(-1,nrow(MyData))
MyData$dummy[MyData$CASE_STATUS == "DENIED"] = 0
MyData$dummy[MyData$CASE_STATUS == "CERTIFIED"] = 1
MyData$dummy[MyData$CASE_STATUS == "CERTIFIED-WITHDRAWN"] = 1
MyData<-subset(MyData,!MyData$dummy %in% MyData$dummy[MyData$dummy == -1])
str(MyData)
summary(MyData)
MyData1<-subset(MyData, MyData$dummy%in%MyData$dummy[MyData$dummy==1])
MyData0<-subset(MyData, MyData$dummy%in%MyData$dummy[MyData$dummy==0])
smp_size <- floor(0.05* nrow(MyData1))
set.seed(123)
newdata_ind <- sample(seq_len(nrow(MyData1)), size = smp_size)
MyData1<-MyData1[newdata_ind, ]
newdata<-bind_rows(MyData0, MyData1)
str(MyData0)
str(MyData1)
head(newdata, n=30)
tail(newdata, n=30)
str(newdata)
summary(newdata)
smp_size <- floor(0.75 * nrow(newdata))
set.seed(12345)
train_ind <- sample(seq_len(nrow(newdata)), size = smp_size)
Training <-newdata[train_ind, ]
Testing <-newdata[-train_ind, ]
summary(Training)
str(Training)
table(Training$dummy)
str(Testing)
summary(Testing)
table(Testing$dummy)
Training$Region<-as.factor(Training$Region)
Testing$Region<-as.factor(Testing$Region)
Training$YEAR<-as.factor(Training$YEAR)
Training$FULL_TIME_POSITION<-as.factor(Training$FULL_TIME_POSITION)
Testing$YEAR<-as.factor(Testing$YEAR)
TestingFULL_TIME_POSITION<-as.factor(Testing$FULL_TIME_POSITION)
Training$FULL_TIME_POSITION = factor(Training$FULL_TIME_POSITION,levels=c("N","Y"),labels=c(1,2))
Training$YEAR= factor(Training$YEAR,levels=c("2011","2012","2013","2014","2015","2016"),labels=c(1,2,3,4,5,6))
Training$FULL_TIME_POSITION<-as.numeric(Training$FULL_TIME_POSITION)
Training$YEAR<-as.numeric(Training$YEAR)
Testing$FULL_TIME_POSITION = factor(Testing$FULL_TIME_POSITION,levels=c("N","Y"),labels=c(1,2))
Testing$YEAR= factor(Testing$YEAR,levels=c("2011","2012","2013","2014","2015","2016"),labels=c(1,2,3,4,5,6))
Testing$FULL_TIME_POSITION<-as.numeric(Testing$FULL_TIME_POSITION)
Testing$YEAR<-as.numeric(Testing$YEAR)
train.logistic <- glm( dummy ~  YEAR + Region+FULL_TIME_POSITION + PREVAILING_WAGE, binomial(link="logit"),Training)
pr <- predict(train.logistic, Training, type="response")
table(actual=Training$dummy, predicted=pr>.5)
#0.6779
pr2 <- predict(train.logistic, Testing, type="response")
table(actual=Testing$dummy, predicted=pr2>.5)
CrossTable(x=Testing$dummy,y=predicted, prop.chisq=FALSE)
#0.676055061
CrossTable(x=Testing$dummy,y=pr2, prop.chisq=FALSE)
CrossTable(x=Testing$dummy,y=pr, prop.chisq=FALSE)
standardize <- function(v) { (v - mean(v)) / sd(v)}
Xtrn <- apply( Training[ ,c("YEAR", "FULL_TIME_POSITION", "PREVAILING_WAGE")]  , 2, standardize)
Xtst <- apply( Testing[ ,c("YEAR", "FULL_TIME_POSITION", "PREVAILING_WAGE")]  , 2, standardize)
Xtrn<-cbind(Xtrn,Training$Region)
Xtst<-cbind(Xtst,Testing$Region)
preds <- knn( Xtrn, Xtst, cl=Training$dummy, k = 5)
CrossTable(x = Testing$dummy, y = preds, prop.chisq=FALSE)
#0.45385299
table(Testing$dummy,preds)
normalize <- function(x) { return ((x - min(x)) / (max(x) - min(x))) }
Trn <- apply( Training[ ,c("dummy","YEAR", "FULL_TIME_POSITION","PREVAILING_WAGE")]  , 2, normalize)
Tst <- apply( Testing[ ,c("dummy","YEAR", "FULL_TIME_POSITION","PREVAILING_WAGE")]  , 2, normalize)
nn2<- neuralnet(dummy ~YEAR+PREVAILING_WAGE+FULL_TIME_POSITION, data =Trn, hidden = 1)
plot(nn2)
preds
columns=c("FULL_TIME_POSITION","YEAR","PREVAILING_WAGE")
testnew<-subset(Tst,select=columns)
str(testnew)
model_results<-neuralnet::compute(nn2, testnew)
predicted_strength <- model_results$net.result
predicted_strength<-sapply(predicted_strength,round,digits=0)
CrossTable(Testing$dummy,predicted_strength )
(15685+3572)/55139
naiveBayesOut <- naiveBayes( factor(Training$dummy) ~ Training$YEAR + Training$Region+Training$FULL_TIME_POSITION +Training$PREVAILING_WAGE, data = Training)
predsNB <- predict( naiveBayesOut, Training, type = "class")
table(predsNB)
str(Training)
str(Testing)
naiveBayesOut
confusionMatrix(Testing$dummy, predicted=pr2>.5)
library(caret)
confusionMatrix(Testing$dummy, predicted=pr2>.5)
confusionMatrix(pr2, Testing$dummy)
confusionMatrix(pr2>.5, Testing$dummy)
confusionMatrix(actual=Testing$dummy, predicted=pr2>.5)
confusionMatrix(Testing$dummy, predicted=pr2>.5)
confusionMatrix(Testing$dummy, pr2>.5)
nn2
rm(list = ls())
h1b_transformed_na <- readRDS("/Users/jaydangi/Downloads/h1bAnalytics-master")
h1b_transformed_na <- readRDS("/Users/jaydangi/Downloads/h1bAnalytics-master/h1b_transformed_without_na.rds")
train_na = h1b_transformed_na[1:1299875,]
test_na = h1b_transformed_na[1299876:2599750,]
test.case.na <- data.frame(CASE_STATUS=rep("None", nrow(test_na)), test_na[,])
test.case.na$CASE_STATUS.1 <- NULL
data.combined.na <- rbind(train_na,test.case.na)
data.combined.na$JOB_TITLE <- as.character(data.combined.na$JOB_TITLE)
data.combined.na$EMPLOYER_NAME <- as.character(data.combined.na$EMPLOYER_NAME)
data.combined.na$CASE_STATUS <- factor(data.combined.na$CASE_STATUS)
data.combined.na$JOB_TITLE <- as.numeric(data.combined.na$JOB_TITLE)
View(data.combined.na)
data.combined.na$JOB_TITLE <- as.numeric(data.combined.na$JOB_TITLE)
data.combined.na$EMPLOYER_NAME <- as.factor(data.combined.na$EMPLOYER_NAME)
View(data.combined.na)
data.combined.na$JOB_TITLE <- as.numeric(data.combined.na$JOB_TITLE)
select <- train_na[1:1000,]
install.packages("randomForest")
library(randomForest)
rf.train.1 <- data.combined.na[1:1000 ,c("FULL_TIME_POSITION","PREVAILING_WAGE")]
rf.label <- as.factor(select$CASE_STATUS)
rf.label <- factor(rf.label)
set.seed(1234)
rf.1 <- randomForest(x= rf.train.1,y=rf.label, importance=TRUE,ntree = 1000)
rf.1
varImpPlot(rf.1)
plot(rf.1)
rf.train.2 <- data.combined.na[1:1000 ,c("FULL_TIME_POSITION","PREVAILING_WAGE","YEAR")]
set.seed(1234)
rf.2 <- randomForest(x= rf.train.2,y=rf.label, importance=TRUE,ntree = 1000)
rf.2
varImpPlot(rf.2)
rf.train.3 <- data.combined.na[1:1000 ,c("FULL_TIME_POSITION","PREVAILING_WAGE","WORKSITE_STATE","YEAR")]
rf.train.3$WORKSITE_STATE <- factor(rf.train.3$WORKSITE_STATE)
set.seed(1234)
rf.3 <- randomForest(x= rf.train.3,y=rf.label, importance=TRUE,ntree = 1000)
rf.3
varImpPlot(rf.3)
rf.train.4 <- data.combined.na[1:1000 ,c("WORKSITE_STATE","PREVAILING_WAGE")]
rf.train.4$WORKSITE_STATE <- factor(rf.train.4$WORKSITE_STATE)
set.seed(1234)
rf.4 <- randomForest(x= rf.train.4,y=rf.label, importance=TRUE,ntree = 1000)
rf.4
varImpPlot(rf.4)
